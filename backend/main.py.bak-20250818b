from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import os, psycopg
from typing import Optional
from decimal import Decimal
from datetime import datetime, date

app = FastAPI()

# ---- CORS (driven by FRONTEND_ORIGIN) ----
# FRONTEND_ORIGIN can be a single origin, a comma-separated list, or "*" to allow all.
# Example: FRONTEND_ORIGIN=https://predictpix.com,https://app.predictpix.com
origins_env = os.getenv("FRONTEND_ORIGIN", "*").strip()
if origins_env == "*" or origins_env == "":
    allowed_origins = ["*"]
else:
    allowed_origins = [o.strip() for o in origins_env.split(",") if o.strip()]

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---- Helpers ----
def _jsonify_rows(cur):
    """Return list[dict] from the current cursor with safe JSON types."""
    cols = [d[0] for d in cur.description]
    items = []
    for row in cur.fetchall():
        obj = {}
        for k, v in zip(cols, row):
            if isinstance(v, Decimal):
                # numeric -> float for JSON
                obj[k] = float(v)
            elif isinstance(v, (datetime, date)):
                obj[k] = v.isoformat()
            else:
                obj[k] = v
        items.append(obj)
    return items

def _db_url_or_500():
    url = os.getenv("DATABASE_URL")
    if not url:
        raise HTTPException(status_code=500, detail="DATABASE_URL missing")
    return url

# ---- Existing endpoints (kept) ----
@app.get("/health")
def health():
    return {"ok": True}

@app.get("/db/ready")
def db_ready():
    url = os.getenv("DATABASE_URL")
    if not url:
        return {"db": "err", "error": "DATABASE_URL missing"}
    try:
        with psycopg.connect(url, connect_timeout=5) as conn:
            with conn.cursor() as cur:
                cur.execute("select 1")
                cur.fetchone()
        return {"db": "ok"}
    except Exception as e:
        return {"db": "err", "error": str(e)[:200]}

# ---- API-prefixed aliases (no behavior change) ----
@app.get("/api/health")
def api_health():
    return health()

@app.get("/api/db/ready")
def api_db_ready():
    return db_ready()

# ---- New: Markets list ----
@app.get("/api/markets")
def list_markets(
    category: Optional[str] = Query(None),
    status: Optional[str] = Query(None),
    tier: Optional[str] = Query(None),
    archived: Optional[bool] = Query(None, description="If provided, filter by is_archived"),
    search: Optional[str] = Query(None, description="ILIKE on question"),
    sort: str = Query("created_at", description="One of: created_at,end_date,liquidity,tier,status"),
    direction: str = Query("desc", description="asc or desc"),
    limit: int = Query(25, ge=1, le=100),
    offset: int = Query(0, ge=0),
):
    """
    Read-only listing from public.markets. Returns items + total count for paging.
    """
    # Whitelist sort to avoid SQL injection
    allowed_sorts = {
        "created_at": "created_at",
        "end_date": "end_date",
        "liquidity": "liquidity",
        "tier": "tier",
        "status": "status",
    }
    sort_col = allowed_sorts.get(sort.lower(), "created_at")
    dir_norm = "ASC" if str(direction).lower() == "asc" else "DESC"

    where, args = [], []
    if category:
        where.append("category = %s"); args.append(category)
    if status:
        where.append("status = %s"); args.append(status)
    if tier:
        where.append("tier = %s"); args.append(tier)
    if archived is not None:
        where.append("is_archived = %s"); args.append(archived)
    if search:
        where.append("question ILIKE %s"); args.append(f"%{search}%")

    where_sql = (" WHERE " + " AND ".join(where)) if where else ""
    select_sql = (
        "SELECT id, question, category, tier, status, "
        "created_at, end_date, liquidity, resolved, resolved_at, outcome "
        "FROM public.markets"
    )
    order_sql = f" ORDER BY {sort_col} {dir_norm} "
    limit_sql = " LIMIT %s OFFSET %s "

    url = _db_url_or_500()
    with psycopg.connect(url) as conn:
        with conn.cursor() as cur:
            # total count for pagination
            cur.execute(f"SELECT count(*) FROM public.markets{where_sql}", args)
            total = cur.fetchone()[0]

            # page of items
            cur.execute(select_sql + where_sql + order_sql + limit_sql, args + [limit, offset])
            items = _jsonify_rows(cur)

    return {"items": items, "page": {"limit": limit, "offset": offset, "total": total}}
